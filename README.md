# NLC Text Generation Project ðŸ§ 

This project explores various Natural Language Computing (NLC) techniques for text generation. It includes implementations and experiments with classic methods like Markov Chains and more advanced approaches like Recurrent Neural Networks (RNNs).

---

## ðŸ“‚ Project Structure

The repository is organized into three main directories, reflecting the different stages of a machine learning workflow: experimentation, data management, and model storage.

NLC_TextGen/
â”œâ”€â”€ 1.notebooks/         # <-- All experimental code and explorations.
â”‚   â”œâ”€â”€ NLC_MarkovChains.ipynb
â”‚   â”œâ”€â”€ RNN_TextGen.ipynb
â”‚   â”œâ”€â”€ .ipynb_checkpoints/ # (Auto-generated by Jupyter, ignored by Git)
â”‚   â””â”€â”€ models/           # (Ignored by Git) For saving experimental models from notebooks.
â”‚
â”œâ”€â”€ 2.data/              # <-- Raw datasets. (Ignored by Git)
â”‚   â””â”€â”€ wikitext/         # Contains the WikiText dataset, likely from Hugging Face.
â”‚
â”œâ”€â”€ 3.model/             # <-- Final, trained models. (Ignored by Git)
â”‚
â”œâ”€â”€ .gitignore           # <-- Specifies files and directories for Git to ignore.
â””â”€â”€ README.md            # <-- This file.

---

## ðŸš€ Getting Started

### Prerequisites

Ensure you have Python 3.8+ installed. It is highly recommended to use a virtual environment to manage dependencies.

### Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/](https://github.com/)[your-username]/NLC_TextGen.git
    cd NLC_TextGen
    ```

2.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows: venv\Scripts\activate
    ```

3.  **Install the required packages:**
    *(You should create a `requirements.txt` file with your project's dependencies)*
    ```bash
    pip install jupyterlab numpy pandas tensorflow scikit-learn
    # Or install from your requirements file:
    # pip install -r requirements.txt
    ```

---

## âš™ï¸ Usage

1.  **Launch Jupyter:** Start JupyterLab to run the notebooks.
    ```bash
    jupyter lab
    ```
2.  **Run Experiments:** Open and run the notebooks located in the `1.notebooks/` directory to train and experiment with the different text generation models.

3.  **Data:** The project is configured to use the WikiText dataset, which should be located in the `2.data/wikitext/` directory.

4.  **Models:** Experimental models generated by the notebooks are saved to `1.notebooks/models/`. The best, finalized models should be saved in the top-level `3.model/` directory.
